{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.stats as stats\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from statsmodels.stats.contingency_tables import mcnemar                                                           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_power(prob_table, dataset_size, alpha=0.05, r=10000):\n",
    "    print(\"Dataset size: \", dataset_size)\n",
    "    if prob_table[0, 1] == prob_table[1, 0]:\n",
    "        raise RuntimeError(\"Power is undefined when the true effect is zero.\")\n",
    "\n",
    "    pvals = []\n",
    "    diffs = []\n",
    "    for i in range(r):  # number of simulations\n",
    "        sample = np.random.multinomial(n=dataset_size, pvals=prob_table.reshape((4,))).reshape((2,2))\n",
    "        acc_diff = (sample[0,1] - sample[1, 0]) / dataset_size\n",
    "        test_results = mcnemar(sample)\n",
    "        pvals.append(test_results.pvalue)\n",
    "        diffs.append(acc_diff)\n",
    "\n",
    "    true_diff = prob_table[0, 1] - prob_table[1, 0]\n",
    "    true_sign = np.sign(true_diff) \n",
    "    sig_diffs = [d for i, d in enumerate(diffs) if pvals[i] <= alpha]\n",
    "    power = len([d for i, d in enumerate(diffs) if pvals[i] <= alpha and np.sign(d) == true_sign]) / r\n",
    "    mean_effect = np.mean(diffs)\n",
    "    type_m = np.mean(np.abs(sig_diffs) / np.abs(true_diff))\n",
    "    type_s = np.mean(np.sign(sig_diffs) != true_sign)\n",
    "    return power, mean_effect, type_m, type_s\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../data/original_datasets/NEG-136-SIMP.txt\") as f:\n",
    "    raw_data = [d.strip(\",\\n\") for d in f.readlines()]\n",
    "\n",
    "\n",
    "data_orig = []\n",
    "for line in raw_data:\n",
    "    y = line.split(\" \")[-1]\n",
    "    x = line.strip(y).strip(\" \")\n",
    "    is_negative = True if \"not\" in line else False\n",
    "    data_orig.append((x, y, is_negative))\n",
    "\n",
    "\n",
    "with open(\"../data/NEG-1500-SIMP-TEMP.txt\") as f:\n",
    "    raw_data = [d.strip(\",\\n\") for d in f.readlines()]\n",
    "\n",
    "\n",
    "data_extended = []\n",
    "for line in raw_data:\n",
    "    y = line.split(\" \")[-1]\n",
    "    x = line.strip(y).strip(\" \")\n",
    "    is_negative = True if \"not\" in line else False\n",
    "    data_extended.append((x, y, is_negative))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model:  bert-large-uncased\n",
      "Orig arrifmative accuracy:  1.0\n",
      "Extended arrifmative accuracy:  0.8\n",
      "----------------------------------------\n",
      "Model:  roberta-base\n",
      "Orig arrifmative accuracy:  0.9444444444444444\n",
      "Extended arrifmative accuracy:  0.7389610389610389\n",
      "----------------------------------------\n",
      "Orig agreement:  0.9444444444444444\n",
      "Extended agreement:  0.8636363636363636\n",
      "----------------------------------------\n",
      "Original dataset powers:\n",
      "Probability table:\n",
      "[[0.         0.        ]\n",
      " [0.05555556 0.94444444]]\n",
      "acc1 = 1.000\n",
      "acc2 = 0.944\n",
      "Dataset size:  36\n",
      "Approx power = 0.013\n",
      "Approx Type-M error = 3.152\n",
      "Approx Type-S error = 0.000\n",
      "----------------------------------------\n",
      "Extended dataset powers:\n",
      "Probability table:\n",
      "[[0.16233766 0.03766234]\n",
      " [0.0987013  0.7012987 ]]\n",
      "acc1 = 0.800\n",
      "acc2 = 0.739\n",
      "Dataset size:  770\n",
      "Approx power = 0.995\n",
      "Approx Type-M error = 1.002\n",
      "Approx Type-S error = 0.000\n"
     ]
    }
   ],
   "source": [
    "model = \"bert-large-uncased\"\n",
    "print(\"Model: \", model)\n",
    "\n",
    "with open(f\"../predictions/NEG-136-SIMP/{model}.txt\") as f:\n",
    "    preds_orig = [ast.literal_eval(d.strip(\"\\n\"))[:5] for d in f.readlines()]\n",
    "\n",
    "# Affirmative accuracy\n",
    "def get_is_correct(label, predictions, is_negative):\n",
    "    if not is_negative:\n",
    "        return label in predictions\n",
    "    return label not in predictions\n",
    "\n",
    "def is_affirmative(data_point):\n",
    "    return \"not\" not in data_point[0]\n",
    "\n",
    "is_correct_orig = [\n",
    "    get_is_correct(data_orig[i][1], d, data_orig[i][2])\n",
    "    for i, d in enumerate(preds_orig) if is_affirmative(data_orig[i])\n",
    "]\n",
    "\n",
    "print(\"Orig arrifmative accuracy: \", np.mean(is_correct_orig))\n",
    "\n",
    "with open(f\"../predictions/NEG-1500-SIMP-TEMP/{model}.txt\") as f:\n",
    "    preds_extended = [d.strip(\"\\n\") for d in f.readlines()]\n",
    "\n",
    "is_correct_extended = [\n",
    "    get_is_correct(data_extended[i][1], d, data_extended[i][2])\n",
    "    for i, d in enumerate(preds_extended) if is_affirmative(data_extended[i])\n",
    "]\n",
    "\n",
    "print(\"Extended arrifmative accuracy: \", np.mean(is_correct_extended))\n",
    "print(\"-\" * 40)\n",
    "\n",
    "model2 = \"roberta-base\"\n",
    "print(\"Model: \", model2)\n",
    "\n",
    "with open(f\"../predictions/NEG-136-SIMP/{model2}.txt\") as f:\n",
    "    preds_orig2 = [ast.literal_eval(d.strip(\"\\n\"))[:5] for d in f.readlines()]\n",
    "\n",
    "is_correct_orig2 = [\n",
    "    get_is_correct(data_orig[i][1], d, data_orig[i][2])\n",
    "    for i, d in enumerate(preds_orig2) if is_affirmative(data_orig[i])\n",
    "]\n",
    "\n",
    "print(\"Orig arrifmative accuracy: \", np.mean(is_correct_orig2))\n",
    "\n",
    "with open(f\"../predictions/NEG-1500-SIMP-TEMP/{model2}.txt\") as f:\n",
    "    preds_extended2 = [d.strip(\"\\n\") for d in f.readlines()]\n",
    "\n",
    "is_correct_extended2 = [\n",
    "    get_is_correct(data_extended[i][1], d, data_extended[i][2])\n",
    "    for i, d in enumerate(preds_extended2) if is_affirmative(data_extended[i])\n",
    "]\n",
    "\n",
    "print(\"Extended arrifmative accuracy: \", np.mean(is_correct_extended2))\n",
    "print(\"-\" * 40)\n",
    "# Model agreement\n",
    "\n",
    "agrees_orig = [\n",
    "    is_correct_orig[i] == is_correct_orig2[i]\n",
    "    for i in range(len(is_correct_orig))\n",
    "]\n",
    "agrees_extended = [\n",
    "    is_correct_extended[i] == is_correct_extended2[i]\n",
    "    for i in range(len(is_correct_extended))\n",
    "]\n",
    "\n",
    "print(\"Orig agreement: \", np.mean(agrees_orig))\n",
    "print(\"Extended agreement: \", np.mean(agrees_extended))\n",
    "\n",
    "print(\"-\" * 40)\n",
    "print(\"Original dataset powers:\")\n",
    "\n",
    "# p_both_correct, p_only_1_correct, p_only_2_correct, p_both_incorrect\n",
    "p_both_correct = np.mean([a and b for a, b in zip(is_correct_orig, is_correct_orig2)])\n",
    "p_only_1_correct = np.mean([a and not b for a, b in zip(is_correct_orig, is_correct_orig2)])\n",
    "p_only_2_correct = np.mean([not a and b for a, b in zip(is_correct_orig, is_correct_orig2)])\n",
    "p_both_incorrect = np.mean([not a and not b for a, b in zip(is_correct_orig, is_correct_orig2)])\n",
    "\n",
    "for p in [p_both_correct, p_only_1_correct, p_only_2_correct, p_both_incorrect]:\n",
    "    assert p >= 0\n",
    "\n",
    "prob_table = np.array([[p_both_incorrect, p_only_2_correct], [p_only_1_correct, p_both_correct]]) \n",
    "print(\"Probability table:\")\n",
    "print(prob_table)\n",
    "print(\"acc1 = {:.3f}\".format(prob_table[1, :].sum()))\n",
    "print(\"acc2 = {:.3f}\".format(prob_table[:, 1].sum()))\n",
    "\n",
    "power, mean_effect, type_m, type_s = compute_power(prob_table, len(is_correct_orig))\n",
    "\n",
    "print(\"Approx power = {:.3f}\".format(power))\n",
    "print(\"Approx Type-M error = {:.3f}\".format(type_m))\n",
    "print(\"Approx Type-S error = {:.3f}\".format(type_s))\n",
    "\n",
    "print(\"-\" * 40)\n",
    "print(\"Extended dataset powers:\")\n",
    "\n",
    "# p_both_correct, p_only_1_correct, p_only_2_correct, p_both_incorrect\n",
    "p_both_correct = np.mean([a and b for a, b in zip(is_correct_extended, is_correct_extended2)])\n",
    "p_only_1_correct = np.mean([a and not b for a, b in zip(is_correct_extended, is_correct_extended2)])\n",
    "p_only_2_correct = np.mean([not a and b for a, b in zip(is_correct_extended, is_correct_extended2)])\n",
    "p_both_incorrect = np.mean([not a and not b for a, b in zip(is_correct_extended, is_correct_extended2)])\n",
    "\n",
    "for p in [p_both_correct, p_only_1_correct, p_only_2_correct, p_both_incorrect]:\n",
    "    assert p >= 0\n",
    "\n",
    "prob_table = np.array([[p_both_incorrect, p_only_2_correct], [p_only_1_correct, p_both_correct]])\n",
    "print(\"Probability table:\")\n",
    "print(prob_table)\n",
    "print(\"acc1 = {:.3f}\".format(prob_table[1, :].sum()))\n",
    "print(\"acc2 = {:.3f}\".format(prob_table[:, 1].sum()))\n",
    "\n",
    "power, mean_effect, type_m, type_s = compute_power(prob_table, len(is_correct_extended))\n",
    "print(\"Approx power = {:.3f}\".format(power))\n",
    "print(\"Approx Type-M error = {:.3f}\".format(type_m))\n",
    "print(\"Approx Type-S error = {:.3f}\".format(type_s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
